{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021073e8-989e-4e5f-be67-4a6015a8c810",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a88c7-a964-43e7-9a41-9a0c511cf535",
   "metadata": {},
   "source": [
    "## 🔑 Core Topics to Learn in Pandas\n",
    "\n",
    "### 1. **Pandas Basics**\n",
    "\n",
    "* What is Pandas? Why use it?\n",
    "* Installing and importing (`import pandas as pd`)\n",
    "* Pandas data structures:\n",
    "\n",
    "  * **Series** (1D)\n",
    "  * **DataFrame** (2D)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Data Input/Output (I/O)**\n",
    "\n",
    "* Reading data:\n",
    "  `pd.read_csv()`, `pd.read_excel()`, `pd.read_json()`, `pd.read_sql()`\n",
    "* Writing data:\n",
    "  `.to_csv()`, `.to_excel()`, `.to_json()`\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Exploring Data**\n",
    "\n",
    "* `df.head()`, `df.tail()`\n",
    "* `df.info()`, `df.shape`\n",
    "* `df.describe()`\n",
    "* Checking columns & index → `df.columns`, `df.index`\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Selection & Indexing**\n",
    "\n",
    "* Column selection: `df['col']`, `df[['col1','col2']]`\n",
    "* Row selection: `.iloc[]` (by position), `.loc[]` (by label)\n",
    "* Boolean indexing: `df[df['age'] > 30]`\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Data Cleaning**\n",
    "\n",
    "* Handling missing values: `df.isnull()`, `df.fillna()`, `df.dropna()`\n",
    "* Removing duplicates: `df.drop_duplicates()`\n",
    "* String operations: `df['col'].str.lower()`, `.str.contains()`\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Data Transformation**\n",
    "\n",
    "* Renaming columns: `df.rename()`\n",
    "* Changing data types: `df.astype()`\n",
    "* Replacing values: `df.replace()`\n",
    "* Apply functions: `df.apply()`, `df.applymap()`\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Sorting & Filtering**\n",
    "\n",
    "* Sorting: `df.sort_values(by='col')`\n",
    "* Filtering conditions: multiple conditions with `&` and `|`\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Aggregation & Grouping**\n",
    "\n",
    "* `df.groupby('col').mean()`\n",
    "* Aggregations: `.sum()`, `.mean()`, `.count()`\n",
    "* Multiple aggregations: `.agg({'col1':'mean', 'col2':'sum'})`\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Merging, Joining & Concatenation**\n",
    "\n",
    "* `pd.concat([df1, df2])`\n",
    "* `pd.merge(df1, df2, on='key')`\n",
    "* Different join types: inner, outer, left, right\n",
    "\n",
    "---\n",
    "\n",
    "### 10. **Reshaping Data**\n",
    "\n",
    "* Pivot tables: `df.pivot_table()`\n",
    "* Melting: `pd.melt()`\n",
    "* Stacking & unstacking\n",
    "\n",
    "---\n",
    "\n",
    "### 11. **Time Series**\n",
    "\n",
    "* Parsing dates: `pd.to_datetime()`\n",
    "* Setting datetime index\n",
    "* Resampling: `df.resample('M').mean()`\n",
    "\n",
    "---\n",
    "\n",
    "### 12. **Visualization (with Pandas)**\n",
    "\n",
    "* `df['col'].plot(kind='hist')`\n",
    "* `df.plot(kind='bar')`, `df.plot(kind='line')`\n",
    "\n",
    "---\n",
    "\n",
    "## 🔥 Extended Core Topics in Pandas\n",
    "\n",
    "### 13. **Advanced Indexing**\n",
    "\n",
    "* MultiIndex (hierarchical indexing):\n",
    "  `df.set_index(['col1','col2'])`\n",
    "  `df.loc[('A', 'B')]`\n",
    "* Index alignment in operations\n",
    "* Reindexing: `df.reindex()`\n",
    "\n",
    "---\n",
    "\n",
    "### 14. **Window Functions**\n",
    "\n",
    "* Rolling window: `df['col'].rolling(7).mean()`\n",
    "* Expanding: `df['col'].expanding().sum()`\n",
    "* Exponentially weighted: `df['col'].ewm(span=5).mean()`\n",
    "\n",
    "---\n",
    "\n",
    "### 15. **Categorical Data**\n",
    "\n",
    "* `pd.Categorical()` for memory-efficient storage\n",
    "* `.cat.codes`, `.cat.categories`\n",
    "* Useful when you have many repeated string labels\n",
    "\n",
    "---\n",
    "\n",
    "### 16. **Performance Optimization**\n",
    "\n",
    "* Vectorization vs loops (`apply` vs native methods)\n",
    "* Using `.query()` and `.eval()` for faster filtering\n",
    "* Chunk processing with `pd.read_csv(..., chunksize=)`\n",
    "* Memory usage check: `df.memory_usage(deep=True)`\n",
    "\n",
    "---\n",
    "\n",
    "### 17. **Sparse & Large Data Handling**\n",
    "\n",
    "* Sparse data structures (`pd.Series.sparse`)\n",
    "* Efficient storage for large datasets\n",
    "* Working with HDF5/Parquet: `pd.read_parquet()`, `to_parquet()`\n",
    "\n",
    "---\n",
    "\n",
    "### 18. **Advanced Merging & Joins**\n",
    "\n",
    "* Merge with multiple keys\n",
    "* Cross joins (`how='cross'`)\n",
    "* Index-based joins\n",
    "\n",
    "---\n",
    "\n",
    "### 19. **Styling & Reporting**\n",
    "\n",
    "* `df.style` for pretty outputs (color scales, highlights)\n",
    "* `.to_html()`, `.to_latex()` for exporting reports\n",
    "\n",
    "---\n",
    "\n",
    "### 20. **Integration with Other Libraries**\n",
    "\n",
    "* Numpy: vectorized operations (`df.values`)\n",
    "* Matplotlib/Seaborn: `.plot()` integration\n",
    "* Scikit-learn: using Pandas DataFrames as ML input/output\n",
    "\n",
    "---\n",
    "\n",
    "### 21. **Advanced Time Series**\n",
    "\n",
    "* Date offsets (`pd.DateOffset`)\n",
    "* Shifting and lagging: `df['col'].shift(1)`\n",
    "* Rolling joins with time-based indexes\n",
    "\n",
    "---\n",
    "\n",
    "### 22. **Multi-Dataset Analysis**\n",
    "\n",
    "* Combining multiple datasets (like in data engineering/ETL pipelines)\n",
    "* `pd.concat()` with hierarchical keys\n",
    "* Panel-like analysis with `groupby` + reshaping\n",
    "\n",
    "---\n",
    "\n",
    "### 23. **Testing & Validation**\n",
    "\n",
    "* Assertions: `pd.testing.assert_frame_equal(df1, df2)`\n",
    "* Data validation with constraints (unique, non-null, ranges)\n",
    "\n",
    "---\n",
    "\n",
    "### 24. **Best Practices & Patterns**\n",
    "\n",
    "* Method chaining (`.pipe()`, `.assign()`) → cleaner code\n",
    "* Writing reusable transformations\n",
    "* Avoiding loops, sticking to vectorization\n",
    "* Consistent column naming conventions\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 📝 Pandas Cheat Sheet (Quick Ref)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'Name':['A','B'], 'Age':[25,30]})\n",
    "\n",
    "# I/O\n",
    "df = pd.read_csv(\"file.csv\")   # read\n",
    "df.to_csv(\"file.csv\")          # write\n",
    "\n",
    "# Inspect\n",
    "df.head(), df.tail()\n",
    "df.info(), df.describe()\n",
    "\n",
    "# Select\n",
    "df['col'], df[['col1','col2']]\n",
    "df.loc[0], df.iloc[0]\n",
    "df[df['Age'] > 25]\n",
    "\n",
    "# Clean\n",
    "df.dropna(), df.fillna(0)\n",
    "df.drop_duplicates()\n",
    "df['col'].str.lower()\n",
    "\n",
    "# Transform\n",
    "df.rename(columns={'A':'a'})\n",
    "df.astype({'Age':float})\n",
    "df.replace({'M':'Male','F':'Female'})\n",
    "df.apply(lambda x: x*2)\n",
    "\n",
    "# Sort & Filter\n",
    "df.sort_values(by='Age')\n",
    "df[(df['Age'] > 25) & (df['Name']=='A')]\n",
    "\n",
    "# Group & Aggregate\n",
    "df.groupby('col').mean()\n",
    "df.agg({'Age':['mean','max']})\n",
    "\n",
    "# Merge & Concatenate\n",
    "pd.concat([df1,df2])\n",
    "pd.merge(df1, df2, on='id', how='left')\n",
    "\n",
    "# Reshape\n",
    "df.pivot_table(values='Age', index='Name', aggfunc='mean')\n",
    "pd.melt(df, id_vars=['Name'])\n",
    "\n",
    "# Time Series\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date').resample('M').mean()\n",
    "\n",
    "# Plot\n",
    "df['Age'].plot(kind='hist')\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aab8a7-7a5b-42f7-83e3-7c421c81cf9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88e92e05-4e51-42bf-b923-750adcaf871e",
   "metadata": {},
   "source": [
    "## 🔰 Beginner Level\n",
    "\n",
    "### 1. Pandas Basics\n",
    "\n",
    "* **Exercise:** Create a Series and DataFrame from Python lists/dicts.\n",
    "* Print shape, columns, index, data types.\n",
    "* **Dataset:** Manual small list or dict.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Data Input/Output (I/O)\n",
    "\n",
    "* **Exercise:** Load a CSV, Excel, and JSON file.\n",
    "* Save the DataFrame back as CSV & Excel.\n",
    "* **Dataset:** Titanic dataset (`titanic.csv`).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Exploring Data\n",
    "\n",
    "* **Exercise:** Use `.head()`, `.tail()`, `.info()`, `.describe()`.\n",
    "* Find column names, row count.\n",
    "* **Dataset:** Titanic dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Selection & Indexing\n",
    "\n",
    "* **Exercise:** Select a single column, multiple columns, rows by index.\n",
    "* Slice rows using `.iloc` and `.loc`.\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Data Cleaning\n",
    "\n",
    "* **Exercise:** Handle missing ages with mean, drop rows with nulls, remove duplicates.\n",
    "* Convert names to lowercase.\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Data Transformation\n",
    "\n",
    "* **Exercise:** Rename columns (`Survived` → `is_survived`), convert Age to `int`.\n",
    "* Replace male/female with 0/1.\n",
    "* Apply a custom function: double the fare.\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Sorting & Filtering\n",
    "\n",
    "* **Exercise:** Sort passengers by Age and Fare.\n",
    "* Select passengers older than 40 and paid more than 50.\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Aggregation & Grouping\n",
    "\n",
    "* **Exercise:** Find average fare by class, survival rate by gender.\n",
    "* Multiple aggregation: min/max age by class.\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Merging, Joining & Concatenation\n",
    "\n",
    "* **Exercise:** Merge Titanic passengers with a new dataset of `class → avg fare`.\n",
    "* Concatenate two DataFrames vertically.\n",
    "* **Dataset:** Titanic + custom dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Reshaping Data\n",
    "\n",
    "* **Exercise:** Create pivot table (avg age by class and gender).\n",
    "* Melt columns like Age, Fare into a long format.\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "### 11. Time Series\n",
    "\n",
    "* **Exercise:** Create a DataFrame of dates and random sales.\n",
    "* Resample to weekly, monthly.\n",
    "* Find moving average of sales.\n",
    "* **Dataset:** Generated with `pd.date_range()`.\n",
    "\n",
    "---\n",
    "\n",
    "### 12. Visualization (with Pandas)\n",
    "\n",
    "* **Exercise:** Plot histogram of Age, bar chart of survival by class, line chart of sales over time.\n",
    "* **Dataset:** Titanic + sales dataset.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Intermediate Level\n",
    "\n",
    "### 13. Advanced Indexing\n",
    "\n",
    "* **Exercise:** Set `['class','sex']` as MultiIndex, slice data.\n",
    "* Reindex to add missing categories.\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "### 14. Window Functions\n",
    "\n",
    "* **Exercise:** Calculate 7-day rolling average of sales.\n",
    "* Expanding sum of sales.\n",
    "* EWM for smoothing.\n",
    "* **Dataset:** Sales data.\n",
    "\n",
    "---\n",
    "\n",
    "### 15. Categorical Data\n",
    "\n",
    "* **Exercise:** Convert Titanic `class` to categorical.\n",
    "* Encode categories → codes.\n",
    "* Compare memory usage before/after.\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "### 16. Performance Optimization\n",
    "\n",
    "* **Exercise:** Compare filtering with `.query()` vs normal boolean indexing.\n",
    "* Chunk read a large CSV (`chunksize=5000`).\n",
    "* **Dataset:** NYC taxi trips dataset (big).\n",
    "\n",
    "---\n",
    "\n",
    "### 17. Sparse & Large Data Handling\n",
    "\n",
    "* **Exercise:** Convert a DataFrame with many zeros to sparse.\n",
    "* Save/load to Parquet for speed.\n",
    "* **Dataset:** Random sparse matrix.\n",
    "\n",
    "---\n",
    "\n",
    "### 18. Advanced Merging & Joins\n",
    "\n",
    "* **Exercise:** Multi-key merge (`class` + `sex`).\n",
    "* Perform left, right, inner, outer joins.\n",
    "* Cross join two datasets.\n",
    "* **Dataset:** Titanic + extra table.\n",
    "\n",
    "---\n",
    "\n",
    "### 19. Styling & Reporting\n",
    "\n",
    "* **Exercise:** Style Titanic survival table with background gradient.\n",
    "* Export to HTML report.\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "### 20. Integration with Other Libraries\n",
    "\n",
    "* **Exercise:** Use NumPy ufuncs on DataFrame.\n",
    "* Pass Pandas DataFrame into Scikit-learn (fit a LogisticRegression).\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## ⚡ Advanced Level\n",
    "\n",
    "### 21. Advanced Time Series\n",
    "\n",
    "* **Exercise:** Shift stock prices by 1 day (lagging).\n",
    "* Use rolling joins with datetime index.\n",
    "* Add 30-day offset.\n",
    "* **Dataset:** Stock price dataset (Yahoo Finance).\n",
    "\n",
    "---\n",
    "\n",
    "### 22. Multi-Dataset Analysis\n",
    "\n",
    "* **Exercise:** Combine sales data from 3 months, analyze trends.\n",
    "* Use hierarchical keys with concat.\n",
    "* **Dataset:** Monthly sales CSVs.\n",
    "\n",
    "---\n",
    "\n",
    "### 23. Testing & Validation\n",
    "\n",
    "* **Exercise:** Create 2 DataFrames and test equality.\n",
    "* Validate column ranges (Age >= 0, Fare >= 0).\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n",
    "\n",
    "### 24. Best Practices & Patterns\n",
    "\n",
    "* **Exercise:** Use method chaining (`.pipe()`, `.assign()`) to clean and analyze Titanic in one line.\n",
    "* Build a reusable transformation function.\n",
    "* **Dataset:** Titanic.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcb7b5-3f86-4807-b903-4b7f73778c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d51ac351-1f22-43aa-b5ef-cbc94f5b8552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (2.3.3)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from matplotlib) (3.2.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\k_dasaradh\\desktop\\ml_practice\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c91473d-d745-4180-a424-6f908253a5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47f9f6bf-f895-4160-a704-2a1010c81637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d520889c-3e1a-4f1d-b3a9-e6cd8a2a56ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:\n",
      " 0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "4    50\n",
      "dtype: int64\n",
      "Values: [10 20 30 40 50]\n",
      "Index: RangeIndex(start=0, stop=5, step=1)\n",
      "Data type: int64\n"
     ]
    }
   ],
   "source": [
    "# From a list\n",
    "numbers = [10, 20, 30, 40, 50]\n",
    "series = pd.Series(numbers)\n",
    "\n",
    "print(\"Series:\\n\", series)\n",
    "print(\"Values:\", series.values)\n",
    "print(\"Index:\", series.index)\n",
    "print(\"Data type:\", series.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b369270-84b6-4068-99be-66fd4d1918a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "       Name  Age         City\n",
      "0    Alice   24     New York\n",
      "1      Bob   27  Los Angeles\n",
      "2  Charlie   22      Chicago\n",
      "3    David   32      Houston\n",
      "\n",
      "Shape: (4, 3)\n",
      "Columns: Index(['Name', 'Age', 'City'], dtype='object')\n",
      "Index: RangeIndex(start=0, stop=4, step=1)\n",
      "Data types:\n",
      " Name    object\n",
      "Age      int64\n",
      "City    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# From a dictionary of lists\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [24, 27, 22, 32],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"DataFrame:\\n\", df)\n",
    "print(\"\\nShape:\", df.shape)      # (rows, columns)\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Index:\", df.index)\n",
    "print(\"Data types:\\n\", df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9763accf-0544-4b5a-8542-556fb24c037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from list of dicts:\n",
      "     Name  Age           City\n",
      "0    Eve   29  San Francisco\n",
      "1  Frank   35        Seattle\n",
      "\n",
      "Shape: (2, 3)\n",
      "Columns: ['Name', 'Age', 'City']\n"
     ]
    }
   ],
   "source": [
    "# From list of dictionaries\n",
    "people = [\n",
    "    {\"Name\": \"Eve\", \"Age\": 29, \"City\": \"San Francisco\"},\n",
    "    {\"Name\": \"Frank\", \"Age\": 35, \"City\": \"Seattle\"},\n",
    "]\n",
    "\n",
    "df2 = pd.DataFrame(people)\n",
    "\n",
    "print(\"DataFrame from list of dicts:\\n\", df2)\n",
    "print(\"\\nShape:\", df2.shape)\n",
    "print(\"Columns:\", df2.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9b13ef9-11c1-469d-b46f-77fd847ddc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Alice\n",
      "1        Bob\n",
      "2    Charlie\n",
      "3      David\n",
      "Name: Name, dtype: object\n",
      "    Name  Age         City\n",
      "0  Alice   24     New York\n",
      "1    Bob   27  Los Angeles\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    4 non-null      object\n",
      " 1   Age     4 non-null      int64 \n",
      " 2   City    4 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 228.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show only column \"Name\"\n",
    "print(df['Name'])\n",
    "\n",
    "# Show first 2 rows\n",
    "print(df.head(2))\n",
    "\n",
    "# Show info about the DataFrame\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a100f-4d15-44a4-8992-b49976fb3fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e97b31c1-361c-4dce-adcf-8913415ccdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "empty_series = pd.Series([])\n",
    "l = [1,2,3,4,5,6]\n",
    "list_series = pd.Series(l)\n",
    "a = np.array([1.1, 2.2, 3.3, 4.4])\n",
    "array_series = pd.Series(a)\n",
    "d = {\"a\": 20, \"b\": 30, \"c\": 10, \"d\": 5}\n",
    "dict_series = pd.Series(d)\n",
    "t = (10, 3, 4,5, 1,3)\n",
    "tuple_series = pd.Series(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee2f4a13-d74a-4172-b234-a84c91564d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: int64\n",
      "0    1.1\n",
      "1    2.2\n",
      "2    3.3\n",
      "3    4.4\n",
      "dtype: float64\n",
      "a    20\n",
      "b    30\n",
      "c    10\n",
      "d     5\n",
      "dtype: int64\n",
      "0    10\n",
      "1     3\n",
      "2     4\n",
      "3     5\n",
      "4     1\n",
      "5     3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(empty_series)\n",
    "print(list_series)\n",
    "print(array_series)\n",
    "print(dict_series)\n",
    "print(tuple_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1f5a5-4c7e-486f-a936-4632611646fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5569bb0-1840-4e15-b881-052012818745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
